
<!DOCTYPE html>
<html lang="en-US">
  <head>

    
    <meta charset="UTF-8">
<title>VAIN - VC</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Abstract" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A demo website for the paper: “VAIN-VC : A one-shot voice conversion using
VGGish based Autoencoders”" />
<meta property="og:description" content="VAIN-VC : A one-shot voice conversion using
VGGish based Autoencoders" />
<link rel="canonical" href="https://sameer-mann.github.io/VoiceConversion/" />
<meta property="og:url" content="https://sameer-mann.github.io/VoiceConversion/" />
<meta property="og:site_name" content="VAIN-VC" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Abstract" />
<script type="application/ld+json">
{"headline":"Abstract","description":"A demo website for the paper: “Many-to-Many Voice Conversion based Feature Disentanglement using Variational Autoencoder”","url":"https://sameer-mann.github.io/VoiceConversion/","@type":"WebSite","name":"VAIN-VC","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
       <meta name="viewport" content="width=device-width, initial-scale=1.0">
<style>
* {
  box-sizing: border-box;
}

.row::after {
  content: "";
  clear: both;
  display: table;
}

[class*="col-"] {
  float: left;
  padding: 15px;
}

html {
  font-family: "Lucida Sans", sans-serif;
}

.header {
  background-color: #9933cc;
  color: #ffffff;
  padding: 15px;
}

.menu ul {
  list-style-type: none;
  margin: 0;
  padding: 0;
}

.menu li {
  padding: 8px;
  margin-bottom: 7px;
  background-color: #33b5e5;
  color: #ffffff;
  box-shadow: 0 1px 3px rgba(0,0,0,0.12), 0 1px 2px rgba(0,0,0,0.24);
}

.menu li:hover {
  background-color: #0099cc;
}

.aside {
  background-color: #33b5e5;
  padding: 15px;
  color: #ffffff;
  text-align: center;
  font-size: 14px;
  box-shadow: 0 1px 3px rgba(0,0,0,0.12), 0 1px 2px rgba(0,0,0,0.24);
}

.footer {
  background-color: #0099cc;
  color: #ffffff;
  text-align: center;
  font-size: 12px;
  padding: 15px;
}

/* For mobile phones: */
[class*="col-"] {
  width: 100%;
}

@media only screen and (min-width: 600px) {
  /* For tablets: */
  .col-s-1 {width: 8.33%;}
  .col-s-2 {width: 16.66%;}
  .col-s-3 {width: 25%;}
  .col-s-4 {width: 33.33%;}
  .col-s-5 {width: 41.66%;}
  .col-s-6 {width: 50%;}
  .col-s-7 {width: 58.33%;}
  .col-s-8 {width: 66.66%;}
  .col-s-9 {width: 75%;}
  .col-s-10 {width: 83.33%;}
  .col-s-11 {width: 91.66%;}
  .col-s-12 {width: 100%;}
}
@media only screen and (min-width: 768px) {
  /* For desktop: */
  .col-1 {width: 8.33%;}
  .col-2 {width: 16.66%;}
  .col-3 {width: 25%;}
  .col-4 {width: 33.33%;}
  .col-5 {width: 41.66%;}
  .col-6 {width: 50%;}
  .col-7 {width: 58.33%;}
  .col-8 {width: 66.66%;}
  .col-9 {width: 75%;}
  .col-10 {width: 83.33%;}
  .col-11 {width: 91.66%;}
  .col-12 {width: 100%;}
}
</style>
  </head>
  <body>
    <!--<a id="skip-to-content" href="#content">Skip to the content.</a>-->

    <header class="page-header" role="banner">
      <!--<h1 class="project-name">Abstract</h1>-->
      <center>
      <h1 class="project-tagline">A demo website for ICRETM-2022</h1>
      
        <a href="https://github.com/Sameer-Mann/VoiceConversion" class="btn">View on GitHub</a>
      
      </center>
      
      <j:if test="${attrs.nogrid==null or attrs.nogrid.equals(false)}">
      <link rel="stylesheet" href="${resURL}/css/responsive-grid.css" type="text/css" />
      </j:if>
    </header>

    <main id="content" class="main-content" role="main">
      
<h1 id="abstract">Abstract</h1>
<p>Autoencoder can learn to model the hidden speech structure in an unsupervised manner and provide a method to perform non parallel voice conversion. In this paper we implemented a method to perform single shot VC using VGGish inspired Variational Autoencoder. To perform the voice conversion we used instance normalization (IN) to separate the speaker and content representations. Objective evaluations show that our method is able to synthesize a voice similar to the target speaker. Our model was able to perform one-shot many to many voice conversions with less artifacts.
</p>

<h1 id="melspectrogram-visualization">Melspectrogram Visualization</h1>

<p>We conducted experiments on melspectrograms feature and realized that the speaker embedding has significant impact to melspectrograms. So to transfer the style of one person to another during the decoding the phase the global style information of the target speaker is used(the skip connections).As it can be seen in the spectrograms the content or the shape of the spectrogram of the target is similar to that of source but in target there are some frequencies which were not present in the source.  </p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Original utterance (Male)</th>
      <th style="text-align: center">Converted utterance (Female)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="tarun_2.png" alt="female" /></td>
      <td style="text-align: center"><img src="tarun_1_to_female_1.png" alt="male" /></td>
    </tr>
    <tr>
      <td style="text-align: center"><audio src="tarun_1.wav" controls="" preload="" size="5"></audio></td>
      <td style="text-align: center"><audio src="tarun_1_to_female1.wav" controls="" preload="" size="5"></audio></td>
    </tr>
  </tbody>
</table>

<h1 id="male--female">Male → Female</h1>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Source</th>
      <th>Target</th>
      <th>VAIN-VC</th>
      <th>ADAIN-VC</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>sample 1</td>
      <td><audio src="tarun_1.wav" controls="" preload="" size="5"></audio></td>
      <td><audio src="female1.wav" controls="" preload="" size="5"></audio></td>
      <td><audio src="tarun_1_to_female1.wav" controls="" preload="" size="5"></audio></td>
      <td><audio src="tarun_1_to_female1_adain.wav" controls="" preload="" size="5"></audio></td>
    </tr>
  </tbody>
</table>

<h1 id="female--male">Female → Male</h1>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Source</th>
      <th>Target</th>
      <th>VAIN-VC</th>
      <th>ADAIN-VC</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>sample 1</td>
      <td><audio src="female1.wav" controls="" preload=""></audio></td>
      <td><audio src="sameer.wav" controls="" preload=""></audio></td>
      <td><audio src="female1_to_sameer.wav" controls="" preload=""></audio></td>
      <td><audio src="female1_to_sameer_adain.wav" controls="" preload=""></audio></td>
    </tr>
  </tbody>
</table>

<h1 id="female--female">Female → Female</h1>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Source</th>
      <th>Target</th>
      <th>VAIN-VC</th>
      <th>ADAIN-VC</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>sample 1</td>
      <td><audio src="female1.wav" controls="" preload=""></audio></td>
      <td><audio src="female2.wav" controls="" preload=""></audio></td>
      <td><audio src="female1_to_female2.wav" controls="" preload=""></audio></td>
      <td><audio src="female1_to_female2_adain.wav" controls="" preload=""></audio></td>
    </tr>
  </tbody>
</table>

<h1 id="male--male">Male → Male</h1>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Source</th>
      <th>Target</th>
      <th>VAIN-VC</th>
      <th>ADAIN-VC</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>sample 1</td>
      <td><audio src="shan1.wav" controls="" preload=""></audio></td>
      <td><audio src="sameer.wav" controls="" preload=""></audio></td>
      <td><audio src="shan1_to_sameer2.wav" controls="" preload=""></audio></td>
      <td><audio src="shan1_to__sameer_adain.wav" controls="" preload=""></audio></td>
    </tr>
  </tbody>
</table>

</table>


      <footer class="site-footer">
        
          <span class="site-footer-owner"><a href="https://github.com/Sameer-Mann/VoiceConversion">VAIN-VC</a> is maintained by <a href="https://github.com/Sameer-Mann">Sameer Mann</a>.</span>
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </main>
  </body>
</html>

